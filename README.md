# Synthetic Vision: Classifying Human vs AI-Generated Art Using CNNs

## Overview

**Synthetic Vision** is a deep learning-based project designed to classify and differentiate between **human-drawn** and **AI-generated** artworks. With the rise of generative models like GANs, Diffusion Models, and Neural Style Transfer, the boundary between authentic human expression and AI-created art has become blurred. This project leverages a **Convolutional Neural Network (CNN)** to distinguish between the two, achieving up to **93% test accuracy**.

The project uses the **AI-ArtBench** dataset with over 180,000 diverse images and explores the challenges, ethics, and performance of machine vision in art authenticity and attribution

## Objectives

### What We Wanted to Discover:

- Can a machine learning model distinguish between AI-generated and human-drawn images?
- What are the precision and recall differences between classes?
- How does style diversity affect model performance?
- Can we build a robust framework for **art authenticity and classification**?

### Why It Matters:

- With AI-generated content on the rise, **authenticity verification** is essential for digital forensics, art marketplaces, and cultural heritage.
- Helps artists, curators, and researchers understand and track the **evolution of AI in visual expression**.
- Fosters interdisciplinary work between computer science, visual arts, and ethics.

## Methodology

### Dataset: \[AI-ArtBench]

- Over **180,000 images**.
- Contains both **human-created art** and images generated by AI models such as **Latent Diffusion** and **Standard Diffusion**.

### Model Architecture

- Custom **CNN architecture** with:

  - 2 Convolutional layers (64 filters, ReLU)
  - 2 MaxPooling layers (2×2)
  - Flattening + Dense layers
  - Output layer with **Softmax activation** (2 classes: human, AI)

### Training Pipeline

- **Image Preprocessing**: resizing (32×32), normalization
- **Data Augmentation**: flip, zoom, rotate
- **Loss Function**: Categorical Cross-Entropy
- **Optimizer**: Adam
- **Evaluation Metrics**: Accuracy, Precision, Recall, F1-Score
- **Early Stopping** & **Checkpointing** used to prevent overfitting

## Results

| Class        | Accuracy | Precision | Recall  | F1-Score |
| ------------ | -------- | --------- | ------- | -------- |
| Human-Drawn  | 93%      | **96%**   | 92%     | 94%      |
| AI-Generated | 93%      | 86%       | **93%** | 89%      |

- Overall accuracy: **93%**
- Balanced classification with slight improvement needed on AI-Generated precision
- Confusion matrix and heatmaps confirm high true positive rates and manageable false positives

## Visualizations

- Validation Loss/Accuracy Trends (15 epochs)
- Confusion Matrix and Class-wise Heatmap
- Art examples correctly and incorrectly classified
- Feature maps and filters (optional visual explanation using Grad-CAM or similar)

## Key Insights

- **CNNs are highly effective** at learning stylistic patterns from low-resolution imagery.
- The model distinguishes **subtle aesthetic cues** between human intuition and machine patterning.
- **AI art is still detectable** — though increasingly difficult with more sophisticated models.
- The project serves as an **early warning system** against untraceable synthetic art.

## Ethical Considerations

- Dataset bias (stylistic, cultural, genre-specific)
- Copyright and IP of both human and AI art
- Lack of interpretability in CNN decisions (black-box)
- Need for **transparency, fairness, and attribution** in generative media

## Future Work

- Incorporate **explainable AI** (e.g., Grad-CAM visualizations).
- Train on **higher resolution datasets** with more stylistic variation.
- Expand model to **multi-class classification** (style, artist origin, model type).
- Explore **contrastive learning** for deeper feature extraction.
